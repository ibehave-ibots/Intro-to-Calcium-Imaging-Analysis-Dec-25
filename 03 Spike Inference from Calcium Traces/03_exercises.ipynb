{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Inference From Calcium Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve, windows\n",
    "import matplotlib.pyplot as plt\n",
    "from oasis.functions import deconvolve, gen_data\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, c1, s1 = map(np.squeeze, gen_data(N=1, seed=5, sn=0.1, framerate=10))\n",
    "y2, c2, s2 = map(np.squeeze, gen_data(N=1, seed=5, sn=0.1, framerate=20))\n",
    "y3, c3, s3 = map(np.squeeze, gen_data(N=1, seed=5, sn=0.1, framerate=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferring spikes from calcium imaging data is a key step in understanding neuronal activity. In this notebook we explore how the fast and discrete events of neural spiking are transformed into the slow and continuous signals observed in calcium imaging. We begin by using convolution to simulate how spike trains generate fluorescence signals, helping us understand the shape and dynamics of calcium responses. Then we reverse the process using the OASIS algorithm to extract likely spike times from observed calcium traces. We also learn how to apply thresholding to convert continuous deconvolution output into discrete spike events. Finally, we save these inferred spike times for further analysis.\n",
    "\n",
    "## How would a spike train appear as a calcium trace? (Convolution)\n",
    "\n",
    "In this section, we will see how calcium signals are produced from spikes using a process called convolution. When a neuron fires, it does not just cause a sharp, brief change in the signal. Instead, it produces a smooth, slowly fading signal that we observe in calcium imaging. We simulate this by convolving a spike train with a calcium kernel which a shape that describes how the signal should look after a single spike. This helps us understand how fast spiking activity is transformed into the slower calcium traces we record.\n",
    "\n",
    "| Code                                                              | Description                                                                                      |\n",
    "|-------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| `windows.boxcar(win_len)`                                         | Create a boxcar kernel of specified length (`win_len`).                                          |\n",
    "| `windows.triang(win_len)`                                         | Create a triangle kernel of specified length (`win_len`).                                        |\n",
    "| `np.exp(-t / tau)`                                                | Create an exponential decay kernel with decay constant `tau`.                                    |\n",
    "| `np.exp(-t / tau_decay) - np.exp(-t / tau_rise)`                  | Create a double exponential decay kernel with rise (`tau_rise`) and decay (`tau_decay`) times.   |\n",
    "| `kernel_unnorm / kernel_unnorm.sum()`                             | Normalize the kernel by dividing by the sum of its elements.                                     |\n",
    "| `convolve(s1, kernel, mode='full')`                               | Convolve the spike train (`s1`) with the kernel, generating a calcium trace.                     |\n",
    "| `plt.plot(kernel)`                                                | Plot the kernel.                                                                                 |\n",
    "\n",
    "#### **Exercises**\n",
    "\n",
    "**Example**: How will my spikes look if they were convolved with a boxcar kernel of window size 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 3\n",
    "kernel_unnorm = windows.boxcar(win_len)\n",
    "kernel = kernel_unnorm / kernel_unnorm.sum()\n",
    "convolved_trace = convolve(s1, kernel, mode='full')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(kernel)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(s1)\n",
    "plt.plot(convolved_trace[:-win_len+1], color='r')\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: How will my spikes look if they were convolved with a triangle kernel of window size 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: How will my spikes look if they were convolved with a triangle kernel of window size 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: How will my spikes look when convolved with an exponential decay kernel with tau of 10 frames and window size of 101 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 10\n",
    "win_len = 101\n",
    "t = np.arange(win_len)\n",
    "kernel_unnorm = np.exp(-t / tau)\n",
    "kernel = kernel_unnorm / kernel_unnorm.sum()\n",
    "convolved_trace = convolve(s1, kernel, mode='full')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(kernel)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(s1)\n",
    "plt.plot(convolved_trace[:-win_len+1], color='r')\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: How will my spikes look when convolved with an exponential decay kernel with tau of 1 frames and window size of 101 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: How will my spikes look when convolved with an exponential decay kernel with tau of 200 frames and window size of 101 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: How will my spikes look when convolved with a double exponential decay kernel with tau rise of 0.1 frame, tau_decay of 1.5 frames, and window size of 101 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_rise = 0.1\n",
    "tau_decay = 1.5\n",
    "win_len = 101\n",
    "t = np.arange(win_len)\n",
    "kernel_unnorm = np.exp(-t / tau_decay) - np.exp(-t / tau_rise)\n",
    "kernel = kernel_unnorm / kernel_unnorm.sum()\n",
    "convolved_trace = convolve(s1, kernel, mode='full')\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(kernel)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(s1)\n",
    "plt.plot(convolved_trace[:-win_len+1], color='r')\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: How will my spikes look when convolved with a double exponential decay kernel with tau rise of 29.9 frame, tau_decay of 30.0 frames, and window size of 101 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: How will my spikes look when convolved with a double exponential decay kernel with tau rise of 0.1 frame, tau_decay of 4.0 frames, and window size of 101 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OASIS\n",
    "\n",
    "Now that we know how spikes generate calcium signals using a kernel, we want to do the reverse: go from calcium traces back to the original spikes. This is done through deconvolution. OASIS is a commonly used algorithm that estimates spike timings by finding a sparse set of events that, when convolved with a known calcium kernel, best matches the observed signal. The output is a continuous signal where higher values suggest stronger or more likely spike events.\n",
    "\n",
    "| Code                        | Description                                                                                                 |\n",
    "| :------------------------------ | :-------------------------------------------------------------------------------------------------------------- |\n",
    "| `plt.subplot(211)`              | Set up the first subplot for plotting.                                                                          |\n",
    "| `plt.subplot(212)`              | Set up the second subplot for plotting.                                                                         |\n",
    "| `deconvolve(y)`                 | Apply the **deconvolution** function to the calcium trace `y` to infer spikes and baseline.                     |\n",
    "| `plt.axhline(baseline)`         | Plot a horizontal line at the estimated **baseline** value.                                                     |\n",
    "| `deconvolve(y, g=(0.9,))`       | Apply **deconvolution** to the calcium trace `y` with the parameter `g=(0.9,)` to modify spike inference.       |\n",
    "| `deconvolve(y, g=(1.8, -0.81))` | Apply **deconvolution** to the calcium trace `y` with the parameter `g=(1.8, -0.81)` to modify spike inference. |\n",
    "\n",
    "#### **Exercises**\n",
    "\n",
    "**Example**: Estimate spikes from calcium trace `y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_trace, estimated_spikes, estimated_baseline, g, _ = deconvolve(y1)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(y1)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(estimated_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Estimate spikes from calcium trace `y2` and also plot the estimated baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Estimate spikes from calcium trace `y3` and also add estimated baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Give g1 co-efficient as 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_trace, estimated_spikes, estimated_baseline, g, _ = deconvolve(y3, g=(0.9,))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(y3)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(estimated_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Give g1 co-efficient as 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Give g1 co-efficient as 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Give g1 co-efficient as 1.8 and g2 as -0.81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Compare the inferred calcium traces with real calcium trace of y1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_trace, estimated_spikes, estimated_baseline, g, _ = deconvolve(y1)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(y1)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(inferred_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Compare the inferred calcium traces with real calcium trace of y2 with g1 as 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Compare the inferred calcium traces with real calcium trace of y1 with g1 as 1.8 and g2 as -0.81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding and Spike times\n",
    "\n",
    "The output from OASIS is continuous, showing how likely or strong each spike might be. But for many kinds of analysis, we need clear events where either a spike happened, or it did not. To do this, we apply a threshold to the OASIS output. Any value above the threshold is considered a spike.\n",
    "\n",
    "| Code                                     | Description                                                |\n",
    "| :------------------------------------------- | :------------------------------------------------------------- |\n",
    "| `np.max(spikes)`                             | Get the **maximum** spike value.                               |\n",
    "| `np.percentile(spikes, 95)`                  | Find the **95th percentile** of spikes.                        |\n",
    "| `np.mean(spikes)`                            | Calculate the **mean** of spikes.                              |\n",
    "| `np.std(spikes)`                             | Compute the **standard deviation** of spikes.                  |\n",
    "| `fr = 10`                                    | Set **sampling frequency** to 10 Hz.                           |\n",
    "| `spk_inds = np.where(spikes > threshold)[0]` | Identify **spike indices** above threshold.                    |\n",
    "| `spk_times = spk_inds / fr`                  | Convert **spike indices** to **times**.                        |\n",
    "| `plt.eventplot(spk_times)`                   | Plot **spike times** as events.                                |\n",
    "| `find_peaks(spikes, height=0.5, distance=5)` | **Detect peaks** in spikes with height > 0.5 and distance > 5. |\n",
    "\n",
    "#### **Exercises**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, inferred_spikes1, _, _, _ = deconvolve(y1)\n",
    "_, inferred_spikes2, _, _, _ = deconvolve(y2)\n",
    "_, inferred_spikes3, _, _, _ = deconvolve(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: For y1, find spike times of all spikes with amplitude larger than 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "fr = 10\n",
    "spk_inds = np.where(inferred_spikes1 > threshold)[0]\n",
    "spk_times = spk_inds / fr\n",
    "plt.eventplot(spk_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: For y1, find spike times of all spikes with amplitude larger than 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: For y1, find spike times of all spikes with amplitude larger than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: For y1, set threshold to be higher than 10% of maximum amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1 * np.max(inferred_spikes1)\n",
    "fr = 10\n",
    "spk_inds = np.where(inferred_spikes1 > threshold)[0]\n",
    "spk_times = spk_inds / fr\n",
    "plt.eventplot(spk_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: For y1, set threshold to be higher than 95th-percentile of the amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: For y1, set threshold to be higher than three-sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: For y1, only get spike times for spikes with amplitudes larger than 0.5 with minimum distance of at least 5 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_inds, properties = find_peaks(inferred_spikes1, height=0.5, distance=5)\n",
    "fr = 10\n",
    "spk_times = spk_inds / fr\n",
    "plt.eventplot(spk_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: For y1, only get spike times for spikes with amplitudes larger than 0.5 with minimum distance of at least 100 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: For y1, only get spike times for spikes with amplitudes larger than 0.5 with minimum distance of at least 10 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Timestamped Data\n",
    "\n",
    "Once we have identified when spikes likely occurred by thresholding, we save the corresponding time points. These timestamped events are useful for further analysis, such as comparing activity across cells, aligning activity to behavioral events, or building summary statistics. In this section, we will save these spike times as an array of indices or timestamps.\n",
    "\n",
    "| Code                                                  | Description                                               |\n",
    "| :-------------------------------------------------------- | :------------------------------------------------------------ |\n",
    "| `np.save('spks1.npy', spk_times1)`                        | Save **spike times** for neuron 1 to a `.npy` file.           |\n",
    "| `spk1 = np.load('spks1.npy')`                             | Load **spike times** for neuron 1 from a `.npy` file.         |\n",
    "| `plt.eventplot(spk2)`                                     | Plot **spike times** for neuron 2 as an event plot.           |\n",
    "| `spks = np.array([spk_times1, spk_times2], dtype=object)` | Create an array of **spike times** for multiple neurons.      |\n",
    "| `spks = np.load('spks_1_2.npy', allow_pickle=True)`       | Load **spike times** for multiple neurons from a `.npy` file. |\n",
    "| `plt.eventplot(spks[1])`                                  | Plot **spike times** for neuron 2 from the loaded data.       |\n",
    "\n",
    "#### **Exercises**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(inferred_spikes1, 95)\n",
    "fr = 10\n",
    "spk_inds = np.where(inferred_spikes1 > threshold)[0]\n",
    "spk_times1 = spk_inds / fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(inferred_spikes2, 95)\n",
    "fr = 20\n",
    "spk_inds = np.where(inferred_spikes2 > threshold)[0]\n",
    "spk_times2 = spk_inds / fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(inferred_spikes3, 95)\n",
    "fr = 30\n",
    "spk_inds = np.where(inferred_spikes3 > threshold)[0]\n",
    "spk_times3 = spk_inds / fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Save `spk_times1` as `spk1.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('spk1.npy', spk_times1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Save `spk_times2` as `spk2.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Save `spk_times3` as `spk3.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Load `spk1.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk1 = np.load('spk1.npy')\n",
    "plt.eventplot(spk1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Load `spk2.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Load `spk3.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Save `spk_times1` and `spk_times1` together as `spk_1_2.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks = np.array([spk_times1, spk_times2], dtype=object)\n",
    "np.save('spk_1_2.npy', spks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Save `spk_times2` and `spk_times3` together as `spk_2_3.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Save `spk_times1`, `spk_times2`, and `spk_times3` together as `spk_1_2_3.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Load `spk_1_2.npy` and plot the events from first neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks = np.load('spk_1_2.npy', allow_pickle=True)\n",
    "plt.eventplot(spks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Load `spk_1_2.npy` and plot the events from second neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Load `spk.npy` and plot the events from the last neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "name": "calim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
